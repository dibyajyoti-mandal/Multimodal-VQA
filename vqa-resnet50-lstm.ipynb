{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a VQA Model using CNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:53.915518Z",
     "iopub.status.busy": "2025-04-04T06:55:53.915302Z",
     "iopub.status.idle": "2025-04-04T06:55:59.077201Z",
     "shell.execute_reply": "2025-04-04T06:55:59.076267Z",
     "shell.execute_reply.started": "2025-04-04T06:55:53.915497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.optim import AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:59.078492Z",
     "iopub.status.busy": "2025-04-04T06:55:59.078135Z",
     "iopub.status.idle": "2025-04-04T06:55:59.61439Z",
     "shell.execute_reply": "2025-04-04T06:55:59.613514Z",
     "shell.execute_reply.started": "2025-04-04T06:55:59.07847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"bhavikardeshna/visual-question-answering-computer-vision-nlp\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:59.617341Z",
     "iopub.status.busy": "2025-04-04T06:55:59.617028Z",
     "iopub.status.idle": "2025-04-04T06:55:59.733312Z",
     "shell.execute_reply": "2025-04-04T06:55:59.732458Z",
     "shell.execute_reply.started": "2025-04-04T06:55:59.617307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:59.735257Z",
     "iopub.status.busy": "2025-04-04T06:55:59.734991Z",
     "iopub.status.idle": "2025-04-04T06:55:59.738859Z",
     "shell.execute_reply": "2025-04-04T06:55:59.738109Z",
     "shell.execute_reply.started": "2025-04-04T06:55:59.735236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_path = r\"/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/data_train.csv\"\n",
    "eval_path = r\"/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/data_eval.csv\"\n",
    "image_path = r\"/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/images\"\n",
    "test_image_list = r\"/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/test_images_list.txt\"\n",
    "train_image_list = r\"/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/train_images_list.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:59.740039Z",
     "iopub.status.busy": "2025-04-04T06:55:59.739711Z",
     "iopub.status.idle": "2025-04-04T06:55:59.871639Z",
     "shell.execute_reply": "2025-04-04T06:55:59.870906Z",
     "shell.execute_reply.started": "2025-04-04T06:55:59.740008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pre_dataset = pd.DataFrame(pd.read_csv(train_path))\n",
    "pre_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:55:59.872637Z",
     "iopub.status.busy": "2025-04-04T06:55:59.872409Z",
     "iopub.status.idle": "2025-04-04T06:56:04.41002Z",
     "shell.execute_reply": "2025-04-04T06:56:04.409013Z",
     "shell.execute_reply.started": "2025-04-04T06:55:59.872618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame(pd.read_csv(train_path))\n",
    "sample_df['image_id'] = sample_df['image_id'] + '.png'\n",
    "\n",
    "samples = sample_df.sample(n=random.randint(10, 15)).reset_index(drop = True)\n",
    "\n",
    "for i, row in samples.iterrows():\n",
    "    image = os.path.join(image_path, row['image_id'])\n",
    "    question = row['question']\n",
    "    answer = row['answer']\n",
    "\n",
    "    img = Image.open(image)\n",
    "\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Q: {question}\\nA: {answer}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer Generate using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.411Z",
     "iopub.status.busy": "2025-04-04T06:56:04.410763Z",
     "iopub.status.idle": "2025-04-04T06:56:04.41456Z",
     "shell.execute_reply": "2025-04-04T06:56:04.413786Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.410957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_API_KEY'] = \"AIzaSyD6fv2qZAcRc30uDjn96CbsM6pUJwLkdFE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.451394Z",
     "iopub.status.busy": "2025-04-04T06:56:04.451122Z",
     "iopub.status.idle": "2025-04-04T06:56:04.478706Z",
     "shell.execute_reply": "2025-04-04T06:56:04.478047Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.451366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(pd.read_csv(train_path))\n",
    "# eval_df = pd.DataFrame(pd.read_csv(eval_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.479994Z",
     "iopub.status.busy": "2025-04-04T06:56:04.479688Z",
     "iopub.status.idle": "2025-04-04T06:56:04.496332Z",
     "shell.execute_reply": "2025-04-04T06:56:04.495695Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.479943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Generate data for train dataset\n",
    "# new_answer = []\n",
    "# for i, row in df.iterrows():\n",
    "#     question = row['question']\n",
    "#     answer = row['answer']\n",
    "#     new_answer.append(generate_answer(\"gemini-1.5-pro\", question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.500816Z",
     "iopub.status.busy": "2025-04-04T06:56:04.500536Z",
     "iopub.status.idle": "2025-04-04T06:56:04.512551Z",
     "shell.execute_reply": "2025-04-04T06:56:04.511977Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.500794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Generate data for eval dataset\n",
    "# new_eval_answer = []\n",
    "# for i, row in eval_df.iterrows():\n",
    "#     question = row['question']\n",
    "#     answer = row['answer']\n",
    "#     new_eval_answer.append(generate_answer(\"gemini-1.5-pro\", question, answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.547759Z",
     "iopub.status.busy": "2025-04-04T06:56:04.547486Z",
     "iopub.status.idle": "2025-04-04T06:56:04.56337Z",
     "shell.execute_reply": "2025-04-04T06:56:04.562763Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.547733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "full_ans_train = r\"/kaggle/input/vqa-fullanswer/train_data.csv\"\n",
    "full_ans_val = r\"/kaggle/input/vqa-fullanswer/eval_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.564383Z",
     "iopub.status.busy": "2025-04-04T06:56:04.564142Z",
     "iopub.status.idle": "2025-04-04T06:56:04.628112Z",
     "shell.execute_reply": "2025-04-04T06:56:04.627382Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.564364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(pd.read_csv(full_ans_train))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T10:00:34.164417Z",
     "iopub.status.busy": "2025-04-04T10:00:34.164078Z",
     "iopub.status.idle": "2025-04-04T10:00:34.198629Z",
     "shell.execute_reply": "2025-04-04T10:00:34.19783Z",
     "shell.execute_reply.started": "2025-04-04T10:00:34.164391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_dataframe = pd.DataFrame(pd.read_csv(full_ans_val))\n",
    "eval_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.629132Z",
     "iopub.status.busy": "2025-04-04T06:56:04.628887Z",
     "iopub.status.idle": "2025-04-04T06:56:04.66177Z",
     "shell.execute_reply": "2025-04-04T06:56:04.660937Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.629111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_qa_pairs(df, output_file='all_pair_qa.csv'):\n",
    "    df[['question', 'response']].to_csv(output_file, index=False)\n",
    "    print(f\"File saved: {output_file}\")\n",
    "\n",
    "create_qa_pairs(dataframe, output_file= r'/kaggle/working/all_pair_qa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.662831Z",
     "iopub.status.busy": "2025-04-04T06:56:04.662598Z",
     "iopub.status.idle": "2025-04-04T06:56:04.67373Z",
     "shell.execute_reply": "2025-04-04T06:56:04.672823Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.662812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataframe['image_id'] = dataframe['image_id'] + '.png'\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:04.674739Z",
     "iopub.status.busy": "2025-04-04T06:56:04.674492Z",
     "iopub.status.idle": "2025-04-04T06:56:08.402917Z",
     "shell.execute_reply": "2025-04-04T06:56:08.402115Z",
     "shell.execute_reply.started": "2025-04-04T06:56:04.674715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "samples = dataframe.sample(n=random.randint(10, 15)).reset_index(drop = True)\n",
    "\n",
    "for i, row in samples.iterrows():\n",
    "    image = os.path.join(image_path, row['image_id'])\n",
    "    question = row['question']\n",
    "    answer = row['response']\n",
    "\n",
    "    img = Image.open(image)\n",
    "\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Q: {question}\\nA: {answer}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:08.404132Z",
     "iopub.status.busy": "2025-04-04T06:56:08.403896Z",
     "iopub.status.idle": "2025-04-04T06:56:08.409366Z",
     "shell.execute_reply": "2025-04-04T06:56:08.40869Z",
     "shell.execute_reply.started": "2025-04-04T06:56:08.404113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    transforms.RandomRotation(30),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:08.410354Z",
     "iopub.status.busy": "2025-04-04T06:56:08.410163Z",
     "iopub.status.idle": "2025-04-04T06:56:14.3006Z",
     "shell.execute_reply": "2025-04-04T06:56:14.299693Z",
     "shell.execute_reply.started": "2025-04-04T06:56:08.410337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:14.301913Z",
     "iopub.status.busy": "2025-04-04T06:56:14.30153Z",
     "iopub.status.idle": "2025-04-04T06:56:15.18715Z",
     "shell.execute_reply": "2025-04-04T06:56:15.186397Z",
     "shell.execute_reply.started": "2025-04-04T06:56:14.30189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:15.188451Z",
     "iopub.status.busy": "2025-04-04T06:56:15.188157Z",
     "iopub.status.idle": "2025-04-04T06:56:15.192572Z",
     "shell.execute_reply": "2025-04-04T06:56:15.191685Z",
     "shell.execute_reply.started": "2025-04-04T06:56:15.188429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def spacy_tokenizer(text):\n",
    "    tokens = []\n",
    "    for token in nlp(text):\n",
    "        if not token.is_punct and not token.is_space: \n",
    "            tokens.append(token.text.lower())\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:15.193708Z",
     "iopub.status.busy": "2025-04-04T06:56:15.193415Z",
     "iopub.status.idle": "2025-04-04T06:56:15.211593Z",
     "shell.execute_reply": "2025-04-04T06:56:15.21074Z",
     "shell.execute_reply.started": "2025-04-04T06:56:15.193675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq = 1):\n",
    "\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(spacy_tokenizer(text)) \n",
    "\n",
    "    vocab = {}\n",
    "    vocab[\"<unk>\"] = 0\n",
    "    vocab[\"<pad>\"] = 1\n",
    "    vocab[\"<sos>\"] = 2\n",
    "    vocab[\"<eos>\"] = 3\n",
    "    \n",
    "    index = 4 \n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:15.212603Z",
     "iopub.status.busy": "2025-04-04T06:56:15.212374Z",
     "iopub.status.idle": "2025-04-04T06:56:15.265753Z",
     "shell.execute_reply": "2025-04-04T06:56:15.265078Z",
     "shell.execute_reply.started": "2025-04-04T06:56:15.212584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "build_vocab({\"Hello, this is Dibyajyoti from IITBHU\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:56:15.26673Z",
     "iopub.status.busy": "2025-04-04T06:56:15.26649Z",
     "iopub.status.idle": "2025-04-04T06:57:59.851154Z",
     "shell.execute_reply": "2025-04-04T06:57:59.850426Z",
     "shell.execute_reply.started": "2025-04-04T06:56:15.266711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_questions = build_vocab(dataframe['question'])\n",
    "vocab_answers = build_vocab(dataframe['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.856331Z",
     "iopub.status.busy": "2025-04-04T06:57:59.856103Z",
     "iopub.status.idle": "2025-04-04T06:57:59.881656Z",
     "shell.execute_reply": "2025-04-04T06:57:59.880855Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.856313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Sample vocab from questions:\")\n",
    "for word, index in list(vocab_questions.items())[:10]:  \n",
    "    print(f\"{word}: {index}\")\n",
    "\n",
    "print(\"\\nSample vocab from answers:\")\n",
    "for word, index in list(vocab_answers.items())[:10]:\n",
    "    print(f\"{word}: {index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.882498Z",
     "iopub.status.busy": "2025-04-04T06:57:59.882318Z",
     "iopub.status.idle": "2025-04-04T06:57:59.897796Z",
     "shell.execute_reply": "2025-04-04T06:57:59.897188Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.882483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "questions_vocab_size = len(vocab_questions)\n",
    "answers_vocab_size = len(vocab_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.898876Z",
     "iopub.status.busy": "2025-04-04T06:57:59.898668Z",
     "iopub.status.idle": "2025-04-04T06:57:59.921115Z",
     "shell.execute_reply": "2025-04-04T06:57:59.920341Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.898858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx2word_answers = {idx: word for word, idx in vocab_answers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.922089Z",
     "iopub.status.busy": "2025-04-04T06:57:59.921872Z",
     "iopub.status.idle": "2025-04-04T06:57:59.940932Z",
     "shell.execute_reply": "2025-04-04T06:57:59.940176Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.922071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Sample vocab from questions:\")\n",
    "for word, index in list(idx2word_answers.items())[:10]:  \n",
    "    print(f\"{word}: {index}\")\n",
    "\n",
    "print(\"\\nSample vocab from answers:\")\n",
    "for word, index in list(idx2word_answers.items())[:10]:  \n",
    "    print(f\"{word}: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.942177Z",
     "iopub.status.busy": "2025-04-04T06:57:59.941882Z",
     "iopub.status.idle": "2025-04-04T06:57:59.957897Z",
     "shell.execute_reply": "2025-04-04T06:57:59.957305Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.942151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def decode_answer(tensor, vocab_dict):\n",
    "    return \" \".join([vocab_dict[idx] for idx in tensor if idx not in {0, 1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.958731Z",
     "iopub.status.busy": "2025-04-04T06:57:59.95852Z",
     "iopub.status.idle": "2025-04-04T06:57:59.977142Z",
     "shell.execute_reply": "2025-04-04T06:57:59.976498Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.958713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_max_len(texts):\n",
    "    max_len = 0\n",
    "    for text in texts:\n",
    "        tokens = spacy_tokenizer(text)\n",
    "        if len(tokens) > max_len:\n",
    "            max_len = len(tokens)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.978131Z",
     "iopub.status.busy": "2025-04-04T06:57:59.977843Z",
     "iopub.status.idle": "2025-04-04T06:57:59.995667Z",
     "shell.execute_reply": "2025-04-04T06:57:59.994873Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.978104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# len_max_question = get_max_len(dataframe['question'])\n",
    "# len_max_answer = get_max_len(dataframe['response'])\n",
    "\n",
    "len_max_question = 24\n",
    "len_max_answer = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:57:59.996802Z",
     "iopub.status.busy": "2025-04-04T06:57:59.996515Z",
     "iopub.status.idle": "2025-04-04T06:58:00.011708Z",
     "shell.execute_reply": "2025-04-04T06:58:00.010994Z",
     "shell.execute_reply.started": "2025-04-04T06:57:59.996761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def text_to_tensor(text, vocab, max_len):\n",
    "    tokens = spacy_tokenizer(text)  \n",
    "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
    "    \n",
    "    indices = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]  \n",
    "\n",
    "    if len(indices) < max_len:  # Padding\n",
    "        indices += [vocab[\"<pad>\"]] * (max_len - len(indices))  \n",
    "    else:  # Truncate\n",
    "        indices = indices[:max_len]  \n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:00.012599Z",
     "iopub.status.busy": "2025-04-04T06:58:00.012406Z",
     "iopub.status.idle": "2025-04-04T06:58:00.036054Z",
     "shell.execute_reply": "2025-04-04T06:58:00.035309Z",
     "shell.execute_reply.started": "2025-04-04T06:58:00.012583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(self, csv_path, image_folder, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.df['image_id'] = self.df['image_id'] + '.png'\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.image_folder, row['image_id'])\n",
    "        question = text_to_tensor(row['question'], vocab_questions, len_max_question)\n",
    "        answer = text_to_tensor(row['response'], vocab_answers, len_max_answer)\n",
    "\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.zeros((3, 224, 224))\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "        \n",
    "        return img, question, answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:00.036899Z",
     "iopub.status.busy": "2025-04-04T06:58:00.036699Z",
     "iopub.status.idle": "2025-04-04T06:58:00.077986Z",
     "shell.execute_reply": "2025-04-04T06:58:00.077399Z",
     "shell.execute_reply.started": "2025-04-04T06:58:00.036882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = VQADataset(full_ans_train, image_path, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:00.078844Z",
     "iopub.status.busy": "2025-04-04T06:58:00.078652Z",
     "iopub.status.idle": "2025-04-04T06:58:00.09898Z",
     "shell.execute_reply": "2025-04-04T06:58:00.098373Z",
     "shell.execute_reply.started": "2025-04-04T06:58:00.078828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_dataset = VQADataset(full_ans_val, image_path, transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=16, shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:00.100238Z",
     "iopub.status.busy": "2025-04-04T06:58:00.099945Z",
     "iopub.status.idle": "2025-04-04T06:58:00.394904Z",
     "shell.execute_reply": "2025-04-04T06:58:00.394195Z",
     "shell.execute_reply.started": "2025-04-04T06:58:00.100211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "sample_image, sample_question, sample_answer = train_dataset[sample_idx]\n",
    "\n",
    "print(f\"Sample index: {sample_idx}\")\n",
    "print(f\"Question Tensor: {sample_question}\")\n",
    "print(f\"Answer Tensor: {sample_answer}\")\n",
    "print(f\"Image Shape: {sample_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:00.400355Z",
     "iopub.status.busy": "2025-04-04T06:58:00.400139Z",
     "iopub.status.idle": "2025-04-04T06:58:02.468425Z",
     "shell.execute_reply": "2025-04-04T06:58:02.467322Z",
     "shell.execute_reply.started": "2025-04-04T06:58:00.400337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, questions, answers in train_loader:\n",
    "    print(f\"Batch size: {images.shape}\")  \n",
    "    print(f\"First Question Tensor: {questions[0]}\")\n",
    "    print(f\"First Answer Tensor: {answers[0]}\")\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:02.471131Z",
     "iopub.status.busy": "2025-04-04T06:58:02.470795Z",
     "iopub.status.idle": "2025-04-04T06:58:04.487393Z",
     "shell.execute_reply": "2025-04-04T06:58:04.486509Z",
     "shell.execute_reply.started": "2025-04-04T06:58:02.471108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for images, questions, answers in eval_loader:\n",
    "    print(f\"Batch size: {images.shape}\") \n",
    "    print(f\"First Question Tensor: {questions[0]}\")\n",
    "    print(f\"First Answer Tensor: {answers[0]}\")\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:04.488814Z",
     "iopub.status.busy": "2025-04-04T06:58:04.48857Z",
     "iopub.status.idle": "2025-04-04T06:58:04.494673Z",
     "shell.execute_reply": "2025-04-04T06:58:04.493837Z",
     "shell.execute_reply.started": "2025-04-04T06:58:04.488793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CNN_Feature_Extractor_pretrained(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Feature_Extractor_pretrained, self).__init__()\n",
    "\n",
    "        resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "\n",
    "        self.fc = nn.Linear(2048, 512)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:04.495887Z",
     "iopub.status.busy": "2025-04-04T06:58:04.495675Z",
     "iopub.status.idle": "2025-04-04T06:58:04.514391Z",
     "shell.execute_reply": "2025-04-04T06:58:04.51354Z",
     "shell.execute_reply.started": "2025-04-04T06:58:04.495869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Question_Encoder(nn.Module):\n",
    "    def __init__(self, questions_vocab_size, embedding_dim = 256, hidden_dim = 512):\n",
    "        super(Question_Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(questions_vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout = 0.2, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        return hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:04.5155Z",
     "iopub.status.busy": "2025-04-04T06:58:04.51522Z",
     "iopub.status.idle": "2025-04-04T06:58:04.5348Z",
     "shell.execute_reply": "2025-04-04T06:58:04.534035Z",
     "shell.execute_reply.started": "2025-04-04T06:58:04.515474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim=512):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 3, hidden_dim)  \n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "    \n",
    "    def forward(self, hidden, combined_feat):\n",
    "        if hidden.dim() > 2:\n",
    "            hidden = hidden.squeeze(0)  \n",
    "        \n",
    "        if hidden.dim() == 1:\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, combined_feat), dim=1)))  # (batch_size, hidden_dim)\n",
    "        attention_weights = F.softmax(self.v(energy), dim=1)  # (batch_size, 1)\n",
    "        \n",
    "        context = attention_weights * combined_feat  # (batch_size, hidden_dim * 2)\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:04.535898Z",
     "iopub.status.busy": "2025-04-04T06:58:04.535637Z",
     "iopub.status.idle": "2025-04-04T06:58:04.558469Z",
     "shell.execute_reply": "2025-04-04T06:58:04.557874Z",
     "shell.execute_reply.started": "2025-04-04T06:58:04.535878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Answer_Decoder(nn.Module):\n",
    "    def __init__(self, answer_vocab_size, embedding_size=256, hidden_dim=512, k_beam = 3):\n",
    "        super(Answer_Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(answer_vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size + 1024, hidden_dim, num_layers=3, dropout = 0.2, batch_first=True)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, answer_vocab_size)\n",
    "\n",
    "        self.k_beam = k_beam\n",
    "    \n",
    "    def forward(self, question_feat, image_feat, answer_seq=None, answer_maxlength=36):\n",
    "        combined_feat = torch.cat((question_feat, image_feat), dim=1)    # (batch_size, 2, hidden_dim)\n",
    "\n",
    "        if answer_seq is not None:\n",
    "            x = self.embedding(answer_seq)\n",
    "            hidden_state = None\n",
    "            outputs = []\n",
    "            \n",
    "            for i in range(x.size(1)):\n",
    "                context, _ = self.attention(hidden_state[0][-1] if hidden_state else question_feat, combined_feat)\n",
    "                lstm_input = torch.cat((x[:, i, :], context), dim=1).unsqueeze(1)\n",
    "                output, hidden_state = self.lstm(lstm_input, hidden_state)\n",
    "                outputs.append(self.fc(output.squeeze(1)))\n",
    "            \n",
    "            return torch.stack(outputs, dim=1)\n",
    "\n",
    "\n",
    "        else:\n",
    "            batch_size = combined_feat.size(0)\n",
    "            device = image_feat.device\n",
    "            end_token = 3 \n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            for b in range(batch_size):\n",
    "                b_question_feat = question_feat[b:b+1]\n",
    "                b_combined_feat = combined_feat[b:b+1]\n",
    "                \n",
    "                beams = [(torch.tensor([[2]], dtype=torch.long, device=device),  # Start token\n",
    "                          0.0,  # Log probability score\n",
    "                          None)]  # Initial hidden state\n",
    "                \n",
    "                completed_beams = []\n",
    "                \n",
    "                for _ in range(answer_maxlength):\n",
    "                    candidates = []\n",
    "                    \n",
    "                    for seq, score, hidden_state in beams:\n",
    "                        if seq[0, -1].item() == end_token:\n",
    "                            completed_beams.append((seq, score, hidden_state))\n",
    "                            continue\n",
    "                        \n",
    "                        x = self.embedding(seq[:, -1])\n",
    "                        \n",
    "                        prev_hidden = hidden_state[0][-1] if hidden_state else b_question_feat\n",
    "                        context, _ = self.attention(prev_hidden, b_combined_feat)\n",
    "                        \n",
    "                        lstm_input = torch.cat((x, context), dim=1).unsqueeze(1)\n",
    "                        \n",
    "                        output, new_hidden = self.lstm(lstm_input, hidden_state)\n",
    "                        \n",
    "                        logits = self.fc(output.squeeze(1))\n",
    "                        log_probs = F.log_softmax(logits, dim=1)\n",
    "                        \n",
    "                        topk_log_probs, topk_indices = log_probs.topk(self.k_beam)\n",
    "                        \n",
    "                        for i in range(self.k_beam):\n",
    "                            next_token = topk_indices[:, i:i+1]\n",
    "                            next_score = score + topk_log_probs[:, i].item()\n",
    "                            next_seq = torch.cat([seq, next_token], dim=1)\n",
    "                            candidates.append((next_seq, next_score, new_hidden))\n",
    "                    \n",
    "                    if not candidates:\n",
    "                        break\n",
    "                    \n",
    "                    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "                    beams = candidates[:self.k_beam]\n",
    "                    \n",
    "                    if all(beam[0][0, -1].item() == end_token for beam in beams):\n",
    "                        completed_beams.extend(beams)\n",
    "                        break\n",
    "                \n",
    "                if completed_beams:\n",
    "                    completed_beams.sort(key=lambda x: x[1], reverse=True)\n",
    "                    best_seq = completed_beams[0][0]\n",
    "                else:\n",
    "                    beams.sort(key=lambda x: x[1], reverse=True)\n",
    "                    best_seq = beams[0][0]\n",
    "                \n",
    "                all_results.append(best_seq)\n",
    "            \n",
    "            max_len = max(seq.size(1) for seq in all_results)\n",
    "            padded_results = []\n",
    "            \n",
    "            for seq in all_results:\n",
    "                if seq.size(1) < max_len:\n",
    "                    padding = torch.full((1, max_len - seq.size(1)), end_token, dtype=torch.long, device=device)\n",
    "                    padded_seq = torch.cat([seq, padding], dim=1)\n",
    "                    padded_results.append(padded_seq)\n",
    "                else:\n",
    "                    padded_results.append(seq)\n",
    "            \n",
    "            return torch.cat(padded_results, dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:04.559486Z",
     "iopub.status.busy": "2025-04-04T06:58:04.559274Z",
     "iopub.status.idle": "2025-04-04T06:58:15.763446Z",
     "shell.execute_reply": "2025-04-04T06:58:15.762437Z",
     "shell.execute_reply.started": "2025-04-04T06:58:04.559467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_image_batch = next(iter(train_loader))[0].to(device)\n",
    "first_questions_batch = next(iter(train_loader))[1].to(device)\n",
    "first_answers_batch = next(iter(train_loader))[2].to(device)\n",
    "\n",
    "cnn_test = CNN_Feature_Extractor_pretrained().to(device)\n",
    "\n",
    "image_feat = cnn_test(first_image_batch)\n",
    "\n",
    "print(\"Input shape:\", first_image_batch.shape)\n",
    "print(\"Output shape:\", image_feat.shape)\n",
    "\n",
    "\n",
    "encoder_test = Question_Encoder(questions_vocab_size).to(device)\n",
    "\n",
    "question_feat = encoder_test(first_questions_batch)\n",
    "\n",
    "print(\"Input shape:\", first_questions_batch.shape) \n",
    "print(\"Output shape:\", question_feat.shape) \n",
    "\n",
    "decoder_test = Answer_Decoder(answers_vocab_size).to(device)\n",
    "\n",
    "predicted_training = decoder_test(question_feat, image_feat, first_answers_batch)\n",
    "predicted_generate = decoder_test(question_feat, image_feat)\n",
    "\n",
    "\n",
    "question_feat = encoder_test(first_questions_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:15.769725Z",
     "iopub.status.busy": "2025-04-04T06:58:15.769401Z",
     "iopub.status.idle": "2025-04-04T06:58:15.795645Z",
     "shell.execute_reply": "2025-04-04T06:58:15.795044Z",
     "shell.execute_reply.started": "2025-04-04T06:58:15.769692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class VQA_Model(nn.Module):\n",
    "    def __init__(self, questions_vocab_size, answers_vocab_size, k_beam = 3):\n",
    "        super(VQA_Model, self).__init__()\n",
    "\n",
    "        self.image_encoder_resnet50_pretrained = CNN_Feature_Extractor_pretrained().to(device)\n",
    "        self.question_encoder = Question_Encoder(questions_vocab_size).to(device)\n",
    "\n",
    "        self.answer_decoder = Answer_Decoder(answers_vocab_size, k_beam = k_beam).to(device)\n",
    "\n",
    "    def forward(self, image, question, answer_seq = None):\n",
    "        image_feat = self.image_encoder_resnet50_pretrained(image)\n",
    "        question_feat = self.question_encoder(question)\n",
    "        output = self.answer_decoder(question_feat, image_feat, answer_seq)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:15.796676Z",
     "iopub.status.busy": "2025-04-04T06:58:15.796456Z",
     "iopub.status.idle": "2025-04-04T06:58:23.558246Z",
     "shell.execute_reply": "2025-04-04T06:58:23.557326Z",
     "shell.execute_reply.started": "2025-04-04T06:58:15.796657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_image_batch = next(iter(train_loader))[0].to(device)\n",
    "first_questions_batch = next(iter(train_loader))[1].to(device)\n",
    "first_answers_batch = next(iter(train_loader))[2].to(device)\n",
    "\n",
    "cnn_test = CNN_Feature_Extractor_pretrained().to(device)\n",
    "\n",
    "image_feat = cnn_test(first_image_batch)\n",
    "\n",
    "print(\"Input shape:\", first_image_batch.shape)\n",
    "print(\"Output shape:\", image_feat.shape)\n",
    "\n",
    "\n",
    "encoder_test = Question_Encoder(questions_vocab_size).to(device)\n",
    "\n",
    "question_feat = encoder_test(first_questions_batch)\n",
    "\n",
    "print(\"Input shape:\", first_questions_batch.shape)\n",
    "print(\"Output shape:\", question_feat.shape)  \n",
    "\n",
    "decoder_test = Answer_Decoder(answers_vocab_size).to(device)\n",
    "\n",
    "predicted_training = decoder_test(question_feat, image_feat, first_answers_batch)\n",
    "predicted_generate = decoder_test(question_feat, image_feat)\n",
    "\n",
    "\n",
    "question_feat = encoder_test(first_questions_batch)\n",
    "print(\"Input shape:\", first_answers_batch.shape)  \n",
    "print(\"Output shape:\", predicted_training.shape)  \n",
    "print(\"Output shape:\", predicted_generate.shape)  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:23.55949Z",
     "iopub.status.busy": "2025-04-04T06:58:23.55922Z",
     "iopub.status.idle": "2025-04-04T06:58:23.608388Z",
     "shell.execute_reply": "2025-04-04T06:58:23.607567Z",
     "shell.execute_reply.started": "2025-04-04T06:58:23.559467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_training.argmax(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:23.609646Z",
     "iopub.status.busy": "2025-04-04T06:58:23.609327Z",
     "iopub.status.idle": "2025-04-04T06:58:23.623275Z",
     "shell.execute_reply": "2025-04-04T06:58:23.622381Z",
     "shell.execute_reply.started": "2025-04-04T06:58:23.609617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:23.62426Z",
     "iopub.status.busy": "2025-04-04T06:58:23.624034Z",
     "iopub.status.idle": "2025-04-04T06:58:24.181387Z",
     "shell.execute_reply": "2025-04-04T06:58:24.18064Z",
     "shell.execute_reply.started": "2025-04-04T06:58:23.624242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "demo_model = VQA_Model(questions_vocab_size, answers_vocab_size, k_beam = 3)\n",
    "\n",
    "output_train = demo_model(first_image_batch, first_questions_batch, first_answers_batch[:, :-1])\n",
    "print('Output train shape:', output_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:02:29.984636Z",
     "iopub.status.busy": "2025-04-04T07:02:29.984346Z",
     "iopub.status.idle": "2025-04-04T07:02:31.575021Z",
     "shell.execute_reply": "2025-04-04T07:02:31.574061Z",
     "shell.execute_reply.started": "2025-04-04T07:02:29.984615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_generate = demo_model(first_image_batch, first_questions_batch)\n",
    "print('Output predtci shape:', output_generate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:25.836515Z",
     "iopub.status.busy": "2025-04-04T06:58:25.836301Z",
     "iopub.status.idle": "2025-04-04T06:58:25.841318Z",
     "shell.execute_reply": "2025-04-04T06:58:25.840472Z",
     "shell.execute_reply.started": "2025-04-04T06:58:25.836486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tensor_to_text(tensor, idx2word):\n",
    "    sentences = []\n",
    "    for seq in tensor:\n",
    "        words = [idx2word[idx.item()] for idx in seq if idx.item() in idx2word]\n",
    "        \n",
    "        if \"<sos>\" in words:\n",
    "            words.remove(\"<sos>\")\n",
    "        sentence = \" \".join(words).split(\"<eos>\")[0]\n",
    "        \n",
    "        sentences.append(sentence.strip())\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:25.842458Z",
     "iopub.status.busy": "2025-04-04T06:58:25.84221Z",
     "iopub.status.idle": "2025-04-04T06:58:27.507601Z",
     "shell.execute_reply": "2025-04-04T06:58:27.506624Z",
     "shell.execute_reply.started": "2025-04-04T06:58:25.842438Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "first_answers_batch = next(iter(train_loader))[2].to(device)\n",
    "answer_text = tensor_to_text(first_answers_batch, idx2word_answers)\n",
    "answer_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:02:41.797418Z",
     "iopub.status.busy": "2025-04-04T07:02:41.797122Z",
     "iopub.status.idle": "2025-04-04T07:02:41.816595Z",
     "shell.execute_reply": "2025-04-04T07:02:41.815734Z",
     "shell.execute_reply.started": "2025-04-04T07:02:41.797395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_text = tensor_to_text(output_generate, idx2word_answers)\n",
    "predicted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T06:58:27.515802Z",
     "iopub.status.busy": "2025-04-04T06:58:27.51535Z",
     "iopub.status.idle": "2025-04-04T06:58:27.533096Z",
     "shell.execute_reply": "2025-04-04T06:58:27.53204Z",
     "shell.execute_reply.started": "2025-04-04T06:58:27.515773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def ngram_precision(reference, candidate, n):\n",
    "    ref_ngrams = Counter([tuple(reference[i:i+n]) for i in range(len(reference)-n+1)])\n",
    "    cand_ngrams = Counter([tuple(candidate[i:i+n]) for i in range(len(candidate)-n+1)])\n",
    "    \n",
    "    overlap = sum(min(cand_ngrams[ngram], ref_ngrams.get(ngram, 0)) for ngram in cand_ngrams)\n",
    "    total = sum(cand_ngrams.values())\n",
    "    \n",
    "    return overlap / total if total > 0 else 0\n",
    "\n",
    "def brevity_penalty(reference, candidate):\n",
    "    ref_len = len(reference)\n",
    "    cand_len = len(candidate)\n",
    "    \n",
    "    if cand_len > ref_len:\n",
    "        return 1\n",
    "    else:\n",
    "        return math.exp(1 - ref_len / cand_len) if cand_len > 0 else 0\n",
    "\n",
    "def compute_bleu(reference_sentences, candidate_sentences, max_n=4):\n",
    "    assert len(reference_sentences) == len(candidate_sentences), \"Số lượng câu tham chiếu và câu dự đoán phải bằng nhau.\"\n",
    "    \n",
    "    bleu_scores = []\n",
    "    for ref, cand in zip(reference_sentences, candidate_sentences):\n",
    "        precisions = [ngram_precision(ref, cand, n) for n in range(1, max_n+1)]\n",
    "        geometric_mean = math.exp(sum(math.log(p) for p in precisions if p > 0) / max_n) if any(precisions) else 0\n",
    "        bp = brevity_penalty(ref, cand)\n",
    "        bleu_scores.append(bp * geometric_mean)\n",
    "    \n",
    "    return sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:00:12.861106Z",
     "iopub.status.busy": "2025-04-04T07:00:12.860672Z",
     "iopub.status.idle": "2025-04-04T07:00:12.867749Z",
     "shell.execute_reply": "2025-04-04T07:00:12.866904Z",
     "shell.execute_reply.started": "2025-04-04T07:00:12.861074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "reference_sentences = [\n",
    "    \"the cat is on the mat\".split(),\n",
    "    \"there is a cat on the mat\".split()\n",
    "]\n",
    "\n",
    "candidate_sentences = [\n",
    "    \"the cat is mat\".split(),\n",
    "    \"there is cat on mat\".split()\n",
    "]\n",
    "\n",
    "bleu_score = compute_bleu(reference_sentences, candidate_sentences)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:03:00.256613Z",
     "iopub.status.busy": "2025-04-04T07:03:00.256318Z",
     "iopub.status.idle": "2025-04-04T07:03:00.263349Z",
     "shell.execute_reply": "2025-04-04T07:03:00.26258Z",
     "shell.execute_reply.started": "2025-04-04T07:03:00.256591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bleu_score = compute_bleu(answer_text, predicted_text)\n",
    "bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:03:03.944148Z",
     "iopub.status.busy": "2025-04-04T07:03:03.943806Z",
     "iopub.status.idle": "2025-04-04T07:03:03.955454Z",
     "shell.execute_reply": "2025-04-04T07:03:03.954438Z",
     "shell.execute_reply.started": "2025-04-04T07:03:03.944118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, train_loader, eval_loader, criterion, optimizer, best_model_path, num_epochs=10, patience=5, device=device):\n",
    "    model.to(device)\n",
    "    best_loss = float('inf')\n",
    "    no_improve_epochs = 0  \n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"eval_loss\": [],\n",
    "        \"bleu_score\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, questions, answers in train_loader:\n",
    "            images, questions, answers = images.to(device), questions.to(device), answers.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images, questions, answers[:, :-1])  \n",
    "            loss = criterion(output.view(-1, output.size(-1)), answers[:, 1:].reshape(-1))  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        bleu_scores = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, questions, answers in eval_loader:\n",
    "                images, questions, answers = images.to(device), questions.to(device), answers.to(device)\n",
    "                output = model(images, questions, answers[:, :-1])\n",
    "\n",
    "                loss = criterion(output.view(-1, output.size(-1)), answers[:, 1:].reshape(-1))\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "                predicted_answers_test = tensor_to_text(model(images, questions), idx2word_answers)\n",
    "                answers_text = tensor_to_text(answers, idx2word_answers)\n",
    "\n",
    "                bleu = compute_bleu(predicted_answers_test, answers_text)\n",
    "                bleu_scores.append(bleu)\n",
    "\n",
    "        avg_eval_loss = eval_loss / len(eval_loader)\n",
    "        avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Evaluation Loss: {avg_eval_loss:.4f}, BLEU Score: {avg_bleu_score:.4f} -- Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        history[\"eval_loss\"].append(avg_eval_loss)\n",
    "        history[\"bleu_score\"].append(avg_bleu_score)\n",
    "\n",
    "        if avg_eval_loss < best_loss:\n",
    "            best_loss = avg_eval_loss\n",
    "            no_improve_epochs = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"Best model saved!\")\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            print(f\"No improvement for {no_improve_epochs}/{patience} epochs.\")\n",
    "\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(\"Early stopping triggered! Training stopped.\")\n",
    "                break\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T07:03:07.486759Z",
     "iopub.status.busy": "2025-04-04T07:03:07.48644Z",
     "iopub.status.idle": "2025-04-04T09:53:05.459065Z",
     "shell.execute_reply": "2025-04-04T09:53:05.45791Z",
     "shell.execute_reply.started": "2025-04-04T07:03:07.486731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VQA_model = VQA_Model(questions_vocab_size, answers_vocab_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
    "optimizer = AdamW(VQA_model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "def train_vqa(train_loader, eval_loader, num_epochs=10):\n",
    "    return train_model(VQA_model, train_loader, eval_loader, criterion, optimizer, r'/kaggle/working/VAQ_model.pth', num_epochs)\n",
    "\n",
    "VQA_model_history = train_vqa(train_loader, eval_loader, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:54:22.611669Z",
     "iopub.status.busy": "2025-04-04T09:54:22.611376Z",
     "iopub.status.idle": "2025-04-04T09:54:22.617806Z",
     "shell.execute_reply": "2025-04-04T09:54:22.617084Z",
     "shell.execute_reply.started": "2025-04-04T09:54:22.611647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    fig, ax1 = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    \n",
    "    ax1[0].plot(epochs, history['train_loss'], label='Train Loss', marker='o', linestyle='-')\n",
    "    ax1[0].plot(epochs, history['eval_loss'], label='Eval Loss', marker='s', linestyle='--')\n",
    "    ax1[0].set_title('Training and Evaluation Loss')\n",
    "    ax1[0].set_xlabel('Epochs')\n",
    "    ax1[0].set_ylabel('Loss')\n",
    "    ax1[0].legend()\n",
    "    ax1[0].grid(True)\n",
    "    \n",
    "    ax1[1].plot(epochs, history['bleu_score'], label='BLEU Score', marker='d', color='g')\n",
    "    ax1[1].set_title('BLEU Score Over Epochs')\n",
    "    ax1[1].set_xlabel('Epochs')\n",
    "    ax1[1].set_ylabel('BLEU Score')\n",
    "    ax1[1].legend()\n",
    "    ax1[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T09:54:37.848858Z",
     "iopub.status.busy": "2025-04-04T09:54:37.848564Z",
     "iopub.status.idle": "2025-04-04T09:54:38.294835Z",
     "shell.execute_reply": "2025-04-04T09:54:38.293904Z",
     "shell.execute_reply.started": "2025-04-04T09:54:37.848837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_training_history(VQA_model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T10:07:47.681254Z",
     "iopub.status.busy": "2025-04-04T10:07:47.680912Z",
     "iopub.status.idle": "2025-04-04T10:07:47.688604Z",
     "shell.execute_reply": "2025-04-04T10:07:47.687656Z",
     "shell.execute_reply.started": "2025-04-04T10:07:47.681227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, question, image_path, ground_truth, idx2word):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    question_tensor = text_to_tensor(question, vocab_questions, len_max_question).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor, question_tensor)\n",
    "    \n",
    "    predicted_answer = tensor_to_text(output, idx2word)[0]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Q: {question}\\nPredicted answer: {predicted_answer}\\nGround Truth: {ground_truth}\", fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T10:08:17.477013Z",
     "iopub.status.busy": "2025-04-04T10:08:17.476656Z",
     "iopub.status.idle": "2025-04-04T10:08:17.481417Z",
     "shell.execute_reply": "2025-04-04T10:08:17.480632Z",
     "shell.execute_reply.started": "2025-04-04T10:08:17.476952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_random_samples(model, eval_dataframe, idx2word):\n",
    "    samples = eval_dataframe.sample(n=15)\n",
    "    \n",
    "    for index, row in samples.iterrows():\n",
    "        question = row['question']\n",
    "        image_path = r'/kaggle/input/visual-question-answering-computer-vision-nlp/dataset/images/' + row['image_id'] + '.png'\n",
    "        ground_truth = row['response']\n",
    "        \n",
    "        predicted_answer = test_model(model, question, image_path, ground_truth, idx2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T10:08:19.604202Z",
     "iopub.status.busy": "2025-04-04T10:08:19.603893Z",
     "iopub.status.idle": "2025-04-04T10:08:23.922258Z",
     "shell.execute_reply": "2025-04-04T10:08:23.921436Z",
     "shell.execute_reply.started": "2025-04-04T10:08:19.604179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_random_samples(VQA_model, eval_dataframe, idx2word_answers)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2264789,
     "sourceId": 3798293,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6913875,
     "sourceId": 11091412,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
